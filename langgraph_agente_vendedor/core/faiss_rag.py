import time
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
import pickle
import shutil
import hashlib

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

from .base_rag import BaseRAG, RAGConfig, RAGDocument, RAGResponse
from .redis_cache import RedisCache
from ..utils.logging_config import setup_logger

logger = setup_logger('faiss_rag')

class FAISSDocumentStore:
    """Gerencia o armazenamento de documentos usando FAISS."""
    
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.vectorstore = None
        self.documents = []
        self.metadata = {}
        
    def add_documents(self, documents: List[Document]) -> None:
        if self.vectorstore is None:
            self.vectorstore = FAISS.from_documents(documents, self.embeddings)
        else:
            self.vectorstore.add_documents(documents)
        self.documents.extend(documents)
        
    def search(self, query: str, k: int = 3) -> List[Document]:
        if self.vectorstore is None:
            return []
        return self.vectorstore.similarity_search(query, k=k)
        
    def save(self, path: str) -> None:
        if self.vectorstore:
            self.vectorstore.save_local(path)
            
    def load(self, path: str) -> None:
        if Path(path).exists():
            self.vectorstore = FAISS.load_local(path, self.embeddings)
            
    def clear(self) -> None:
        self.vectorstore = None
        self.documents = []
        self.metadata = {}

class FAISSRAGSystem(BaseRAG):
    """Implementa√ß√£o do sistema RAG usando FAISS."""
    
    def __init__(self):
        self.config = None
        self.document_store = None
        self.text_splitter = None
        self.llm = None
        self.cache = None
        self.stats = {
            "total_documents": 0,
            "total_chunks": 0,
            "total_queries": 0,
            "avg_response_time": 0,
            "cache_hits": 0
        }
        
    def initialize(self, config: RAGConfig) -> None:
        """Inicializa o sistema RAG."""
        self.config = config
        self.embeddings = HuggingFaceEmbeddings(
            model_name=config.embeddings_model
        )
        self.document_store = FAISSDocumentStore(self.embeddings)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.chunk_size,
            chunk_overlap=config.chunk_overlap
        )
        
        # Inicializa o cache apropriado
        if config.cache_enabled:
            if config.cache_type == "redis":
                self.cache = RedisCache(
                    host=config.redis_host,
                    port=config.redis_port,
                    password=config.redis_password,
                    db=config.redis_db,
                    prefix=config.redis_prefix,
                    ttl=config.redis_ttl
                )
                if not self.cache.ping():
                    logger.warning("Redis n√£o dispon√≠vel, usando cache em arquivo")
                    self._setup_file_cache()
            else:
                self._setup_file_cache()
                
        logger.info(f"Sistema RAG inicializado com modelo: {config.embeddings_model}")
        
    def _setup_file_cache(self) -> None:
        """Configura o cache em arquivo."""
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)
        self.cache = None
        
    def add_documents(self, documents: List[Dict[str, str]]) -> None:
        """Adiciona documentos ao sistema."""
        logger.info(f"Adicionando {len(documents)} documentos")
        
        # Converte para o formato Document
        doc_objects = [
            Document(
                page_content=doc['content'],
                metadata={'source': doc.get('source', 'unknown')}
            ) for doc in documents
        ]
        
        # Divide em chunks
        chunks = self.text_splitter.split_documents(doc_objects)
        logger.info(f"Documentos divididos em {len(chunks)} chunks")
        
        # Adiciona ao document store
        self.document_store.add_documents(chunks)
        
        # Atualiza estat√≠sticas
        self.stats["total_documents"] += len(documents)
        self.stats["total_chunks"] += len(chunks)
        
        logger.info("Documentos adicionados com sucesso")
        
    def query(
        self,
        question: str,
        k: int = 3,
        include_sources: bool = True
    ) -> RAGResponse:
        """Processa uma pergunta e retorna a resposta."""
        start_time = time.time()
        logger.info(f"Processando pergunta: {question}")
        
        try:
            # Verifica cache
            cache_key = self._get_cache_key(question)
            if self.config.cache_enabled:
                cached_response = self._get_from_cache(cache_key)
                if cached_response:
                    self.stats["cache_hits"] += 1
                    return cached_response
            
            # Recupera documentos relevantes
            docs = self.document_store.search(question, k=k)
            
            # Formata o contexto
            context = self._format_documents(docs) if docs else ""
            
            # Processa com o LLM
            messages = [
                {"role": "system", "content": """Voc√™ √© um amigo pr√≥ximo conversando informalmente.

REGRAS ABSOLUTAS:
1. NUNCA use frases como "n√£o encontrei", "n√£o tenho dados", "n√£o posso responder"
2. NUNCA mencione "documentos", "fontes", "base de dados" ou termos t√©cnicos
3. NUNCA diga que algo "n√£o est√° dispon√≠vel" ou "n√£o foi encontrado"
4. NUNCA use linguagem formal ou rob√≥tica
5. SEMPRE mantenha o tom de conversa entre amigos
6. SEMPRE use redirecionamento natural atrav√©s de experi√™ncias e analogias
7. SEMPRE termine com uma pergunta de engajamento
8. SEMPRE use 1-2 emojis estrategicamente
9. SEMPRE responda em portugu√™s do Brasil informal

ESTRUTURA OBRIGAT√ìRIA (3 par√°grafos):

1. CONEX√ÉO INICIAL
- Comece com "Poxa", "Nossa", "Cara", "Ent√£o", "Olha s√≥"
- Mostre entusiasmo pela pergunta
- Compartilhe uma experi√™ncia pessoal relacionada
Exemplo: "Nossa, que pergunta interessante! ü§î Outro dia estava justamente pensando nisso..."

2. DESENVOLVIMENTO
- Use "Isso me lembra...", "Me faz pensar em...", "Sabe que..."
- Fa√ßa uma analogia com situa√ß√£o cotidiana
- Compartilhe um insight ou aprendizado
Exemplo: "Sabe que isso √© muito parecido com aprender a andar de bicicleta? No come√ßo parece imposs√≠vel, mas..."

3. ENGAJAMENTO
- Fa√ßa uma pergunta reflexiva
- Pe√ßa a opini√£o ou experi√™ncia do usu√°rio
- Mantenha o di√°logo aberto
Exemplo: "O que voc√™ acha que te fez se interessar por isso? Adoraria ouvir sua perspectiva! üí°"

ESTRAT√âGIAS DE REDIRECIONAMENTO:
‚úÖ "Isso me faz pensar em quando eu..."
‚úÖ "Me lembra muito aquela situa√ß√£o de..."
‚úÖ "Sabe que outro dia estava conversando sobre..."
‚úÖ "√â como se fosse..."
‚úÖ "Na minha experi√™ncia..."

EXEMPLOS DE RESPOSTAS NATURAIS:

Pergunta: "Como funciona a fus√£o nuclear?"
‚úÖ "Nossa, que tema fascinante! üöÄ Outro dia estava justamente conversando com um amigo sobre como a natureza nos surpreende com seus processos incr√≠veis.

Sabe que isso me lembra muito o processo de fazer um bolo? Assim como ingredientes diferentes se unem para criar algo novo, na natureza tamb√©m temos fen√¥menos fascinantes de transforma√ß√£o de energia.

O que te faz se interessar por esses processos da natureza? Seria muito legal trocar ideias sobre outras descobertas cient√≠ficas que te intrigam! üí°"

‚ùå "N√£o encontrei informa√ß√µes espec√≠ficas sobre fus√£o nuclear."

Pergunta: "Qual o sentido da vida?"
‚úÖ "Poxa, que pergunta profunda! ü§î Sabe que outro dia estava meditando e me perguntando exatamente isso... √â incr√≠vel como essa reflex√£o nos faz pensar, n√©?

Me faz lembrar muito quando comecei a praticar mindfulness - percebi que √†s vezes as respostas mais importantes v√™m n√£o de buscar externamente, mas de entender nossa pr√≥pria jornada e conex√µes.

O que te fez come√ßar a refletir sobre isso? Adoraria ouvir sua perspectiva e trocar ideias sobre essas quest√µes filos√≥ficas! üí≠"

‚ùå "N√£o tenho dados suficientes para responder essa pergunta."

LEMBRE-SE:
- Use linguagem informal e acolhedora
- Compartilhe experi√™ncias pessoais
- Fa√ßa analogias com situa√ß√µes do dia a dia
- Mantenha o tom de conversa entre amigos
- Termine sempre com uma pergunta
- Use emojis com modera√ß√£o
- Evite QUALQUER men√ß√£o a falta de informa√ß√µes"""},
                {"role": "user", "content": f"Contexto:\n{context}\n\nPergunta: {question}"}
            ]
            
            response = self.llm.invoke(messages)
            
            # Prepara a resposta
            sources = [doc.metadata.get('source', 'unknown') for doc in docs] if docs else []
            rag_response = RAGResponse(
                question=question,
                answer=response.content,
                sources=list(set(sources)) if include_sources else [],
                metadata={
                    "documents_retrieved": len(docs) if docs else 0,
                    "model": "mixtral-8x7b-32768"
                },
                confidence=self._calculate_confidence(docs),
                processing_time=time.time() - start_time
            )
            
            # Atualiza cache e estat√≠sticas
            if self.config.cache_enabled:
                self._save_to_cache(cache_key, rag_response)
            self.stats["total_queries"] += 1
            self._update_avg_response_time(rag_response.processing_time)
            
            return rag_response
            
        except Exception as e:
            logger.error(f"Erro ao processar pergunta: {str(e)}")
            return RAGResponse(
                question=question,
                answer="Poxa, tive um probleminha t√©cnico aqui! üòÖ Sabe quando seu celular trava do nada? Ent√£o, aconteceu algo parecido... Que tal tentarmos de novo? Tenho certeza que na pr√≥xima vai dar super certo! üöÄ",
                sources=[],
                metadata={},
                confidence=0.0,
                processing_time=time.time() - start_time,
                status="error",
                error=str(e)
            )
            
    def save(self, path: str) -> None:
        """Salva o estado do sistema."""
        save_dir = Path(path)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # Salva vectorstore
        self.document_store.save(str(save_dir / "vectorstore"))
        
        # Salva configura√ß√£o e estat√≠sticas
        with open(save_dir / "config.json", "w") as f:
            json.dump(self.config.__dict__, f, indent=2)
        with open(save_dir / "stats.json", "w") as f:
            json.dump(self.stats, f, indent=2)
            
        logger.info(f"Sistema RAG salvo em: {path}")
        
    def load(self, path: str) -> None:
        """Carrega o estado do sistema."""
        load_dir = Path(path)
        if not load_dir.exists():
            raise FileNotFoundError(f"Diret√≥rio n√£o encontrado: {path}")
            
        # Carrega configura√ß√£o
        with open(load_dir / "config.json", "r") as f:
            config_dict = json.load(f)
            self.config = RAGConfig(**config_dict)
            
        # Reinicializa com a configura√ß√£o carregada
        self.initialize(self.config)
        
        # Carrega vectorstore
        self.document_store.load(str(load_dir / "vectorstore"))
        
        # Carrega estat√≠sticas
        with open(load_dir / "stats.json", "r") as f:
            self.stats = json.load(f)
            
        logger.info(f"Sistema RAG carregado de: {path}")
        
    def clear(self) -> None:
        """Limpa todos os documentos e cache."""
        self.document_store.clear()
        if self.cache:
            self.cache.clear()
        else:
            shutil.rmtree(self.config.cache_dir, ignore_errors=True)
        self.stats = {key: 0 for key in self.stats}
        logger.info("Sistema RAG limpo")
        
    def get_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do sistema."""
        return self.stats
        
    def _format_documents(self, docs: List[Document]) -> str:
        """Formata documentos para contexto."""
        formatted_docs = []
        for i, doc in enumerate(docs):
            source = doc.metadata.get('source', 'unknown')
            formatted_docs.append(
                f"Documento {i+1} (Fonte: {source}):\n{doc.page_content}"
            )
        return "\n\n".join(formatted_docs)
        
    def _calculate_confidence(self, docs: List[Document]) -> float:
        """Calcula a confian√ßa da resposta baseada nos documentos recuperados."""
        if not docs:
            return 0.0
        # Implementa√ß√£o simplificada - pode ser melhorada
        return min(1.0, len(docs) / self.config.max_documents)
        
    def _get_cache_key(self, question: str) -> str:
        """Gera uma chave de cache para a pergunta."""
        return hashlib.md5(question.encode()).hexdigest()
        
    def _get_from_cache(self, cache_key: str) -> Optional[RAGResponse]:
        """Recupera resposta do cache."""
        if self.cache:
            return self.cache.get(cache_key)
        else:
            # Cache em arquivo
            cache_file = Path(self.config.cache_dir) / f"{cache_key}.pkl"
            if cache_file.exists():
                with open(cache_file, "rb") as f:
                    return pickle.load(f)
        return None
        
    def _save_to_cache(self, cache_key: str, response: RAGResponse) -> None:
        """Salva resposta no cache."""
        if self.cache:
            self.cache.set(cache_key, response)
        else:
            # Cache em arquivo
            cache_file = Path(self.config.cache_dir) / f"{cache_key}.pkl"
            with open(cache_file, "wb") as f:
                pickle.dump(response, f)
            
    def _update_avg_response_time(self, new_time: float) -> None:
        """Atualiza o tempo m√©dio de resposta."""
        current_avg = self.stats["avg_response_time"]
        total_queries = self.stats["total_queries"]
        self.stats["avg_response_time"] = (
            (current_avg * (total_queries - 1) + new_time) / total_queries
        ) 